[project]
name = "asl-video-generator"
version = "0.1.0"
description = "Cloud pipeline for generating photorealistic ASL avatar videos from English text"
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
    # Core ML - MPS-compatible versions
    "torch>=2.2.0",
    "diffusers>=0.27.0",
    "transformers>=4.40.0",
    "accelerate>=0.28.0",

    # LLM providers
    "openai>=1.0",
    "google-generativeai>=0.5.0",
    "ollama>=0.2.0",  # Local LLM support

    # Pose extraction and processing
    "mediapipe>=0.10.11",
    "controlnet-aux>=0.0.8",

    # Data validation and serialization
    "pydantic>=2.0",
    "pydantic-settings>=2.0",

    # Database for pose dictionary
    "sqlalchemy>=2.0",

    # Numerical computing
    "numpy>=1.26.0",
    "scipy>=1.12.0",
    "einops>=0.7.0",

    # Image and video processing
    "pillow>=10.2.0",
    "imageio[ffmpeg]>=2.34.0",
    "opencv-python>=4.9.0",

    # HTTP and async
    "httpx>=0.27.0",

    # Utilities
    "python-dotenv>=1.0.0",
    "tqdm>=4.66.0",
    "psutil>=5.9.0",  # Memory monitoring
]

[project.optional-dependencies]
dev = [
    "pytest>=8.0.0",
    "pytest-asyncio>=0.23.0",
    "ruff>=0.3.0",
    "mypy>=1.9.0",
]

[project.scripts]
asl-generate = "asl_video_generator.cli:main"
asl-translate = "asl_video_generator.cli:translate_cmd"
asl-pose = "asl_video_generator.cli:pose_cmd"
asl-render = "asl_video_generator.cli:render_cmd"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src/asl_video_generator"]

[tool.uv]
package = true

[tool.ruff]
line-length = 100
target-version = "py311"

[tool.ruff.lint]
select = ["E", "F", "I", "UP", "B"]

[tool.mypy]
python_version = "3.11"
strict = true
ignore_missing_imports = true
